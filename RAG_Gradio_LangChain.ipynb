{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucaokylong/LLM_learning/blob/main/RAG_Gradio_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-1vm2uucv8-f"
      },
      "outputs": [],
      "source": [
        "api_key = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zs4KtHZkoyug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cài đặt thư viện cần thiết"
      ],
      "metadata": {
        "id": "dg7jTqcFwCyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet -U langchain chromadb langchain-openai pypdf gradio"
      ],
      "metadata": {
        "id": "ftIUHY5wwEZi"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "da-8aK50wFgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xử lí văn bản PDF"
      ],
      "metadata": {
        "id": "gLTxOgriwHeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=50)\n",
        "loader = PyPDFLoader(r\"/content/A_UAV-Based_Aircraft_Surface_Defect_Inspection_System_via_External_Constraints_and_Deep_Learning.pdf\")\n",
        "splits = loader.load_and_split(text_splitter)"
      ],
      "metadata": {
        "id": "bybSQzaLwJ6U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đưa văn bản thành Embeddings và Lưu trữ vào vectorstore"
      ],
      "metadata": {
        "id": "pFPWwgYJyBmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=emb)"
      ],
      "metadata": {
        "id": "it52CDG3w1AL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xây Dựng Gradio"
      ],
      "metadata": {
        "id": "ONQrYnBlyO5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import OpenAI\n",
        "\n",
        "llm = OpenAI(api_key=api_key)\n",
        "\n",
        "RAG_PROMPT = \"\"\"Nhiệm vụ của bạn là trả lời câu hỏi hoặc tóm tắt văn bản của người dùng dựa trên dữ liệu được cho.\n",
        "Phải trả lời càng dài càng tốt.\n",
        "Nếu dữ liệu được cho không liên quan đến câu hỏi hoặc yêu cầu, vui lòng trả lời \"Tôi không biết\"\n",
        "---\n",
        "Dữ liệu: {context}\n",
        "---\n",
        "Câu hỏi: {question}\n",
        "---\n",
        "Trả lời:\"\"\"\n",
        "\n",
        "def predict(message, history):\n",
        "    history_openai_format = []\n",
        "    for human, assistant in history:\n",
        "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
        "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
        "    docs = vectorstore.similarity_search(message)\n",
        "    context = docs[0].page_content\n",
        "    history_openai_format.append({\"role\": \"user\", \"content\": RAG_PROMPT.format(context=context, question=message)})\n",
        "\n",
        "    response = llm.chat.completions.create(model='gpt-3.5-turbo',\n",
        "      messages= history_openai_format,\n",
        "      temperature=1.0,\n",
        "      stream=True)\n",
        "\n",
        "\n",
        "    partial_message = \"\"\n",
        "    for chunk in response:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "              partial_message = partial_message + chunk.choices[0].delta.content\n",
        "              yield partial_message\n",
        "\n",
        "\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "688-dynpyQXx",
        "outputId": "9100c5be-ee75-47a1-ca83-e1c7e31dc3d9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ee510b1cdf7da214bf.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee510b1cdf7da214bf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5YvTm3cy4Bi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}